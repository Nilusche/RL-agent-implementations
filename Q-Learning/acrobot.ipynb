{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99702029, -0.0771398 ,  0.99802939,  0.06274821, -0.00786349,\n",
       "       -0.03986648])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"Acrobot-v1\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9976714  -0.06820394  0.99913902  0.04148749  0.09487007 -0.16780855]\n",
      "[ 0.99851536 -0.05447081  0.99944044  0.03344864  0.03980326  0.09061267]\n",
      "[ 0.99921918 -0.03950985  0.99908681  0.04272651  0.10714042  0.00307536]\n",
      "[ 9.99999991e-01 -1.30983194e-04  9.99998570e-01  1.69106736e-03\n",
      "  2.77248327e-01 -3.99961165e-01]\n",
      "[ 0.99861935  0.05252999  0.9972709  -0.07382926  0.23663898 -0.33484695]\n",
      "[ 0.99597392  0.08964344  0.99225162 -0.12424461  0.12656124 -0.1578329 ]\n",
      "[ 0.9949355   0.1005154   0.99113626 -0.13284922 -0.01961456  0.07383396]\n",
      "[ 0.99543338  0.09545883  0.9915072  -0.13005177 -0.03010572 -0.046793  ]\n",
      "[ 0.99604097  0.08889533  0.98851833 -0.15110102 -0.0352038  -0.16302469]\n",
      "[ 0.99666727  0.08157425  0.98128507 -0.19256068 -0.03818159 -0.25160635]\n",
      "[ 0.99816383  0.06057198  0.97690904 -0.21365564 -0.1684583   0.03612507]\n",
      "[ 0.99985316  0.01713629  0.98350801 -0.18086457 -0.25634813  0.28592568]\n",
      "[ 0.9993142  -0.03702879  0.99417037 -0.10782061 -0.27219085  0.4314522 ]\n",
      "[ 0.99734231 -0.07285823  0.99859571 -0.05297747 -0.07790158  0.10411222]\n",
      "[ 0.99681361 -0.07976603  0.99939927 -0.03465679  0.01049168  0.07519349]\n",
      "[ 0.99664322 -0.08186757  0.99994561  0.01042949 -0.02965315  0.36743204]\n",
      "[ 0.9959285  -0.09014672  0.99430369  0.10658415 -0.04847474  0.57776735]\n",
      "[ 0.99511108 -0.09876202  0.97306219  0.2305428  -0.03199015  0.65719515]\n",
      "[ 0.99493046 -0.10056528  0.93589737  0.35227278  0.01808474  0.59487241]\n",
      "[ 0.99589539 -0.09051175  0.89471399  0.44663954  0.08313829  0.42119576]\n",
      "[ 0.99767525 -0.06814755  0.86554138  0.50083741  0.13738801  0.18971786]\n",
      "[ 0.99967744 -0.02539721  0.87462393  0.484802    0.28107378 -0.36430436]\n",
      "[ 0.99865006  0.05194274  0.93834807  0.34569192  0.47545306 -1.13625719]\n",
      "[ 0.99167147  0.12879323  0.99041184  0.13814625  0.27399727 -0.95843379]\n",
      "[ 0.98370164  0.17980848  0.99668065 -0.08141054  0.2243352  -1.19564507]\n",
      "[ 0.98038526  0.1970907   0.95957221 -0.28146255 -0.05831504 -0.80550999]\n",
      "[ 0.98777875  0.15586257  0.9235202  -0.38354979 -0.35408391 -0.26768004]\n",
      "[ 0.99877377  0.04950705  0.93589281 -0.35228489 -0.69218595  0.58251199]\n",
      "[ 0.99664573 -0.08183693  0.97047012 -0.24122135 -0.59221428  0.54035717]\n",
      "[ 0.98213881 -0.18815778  0.99214382 -0.12510251 -0.45636199  0.60455172]\n",
      "[ 0.97079669 -0.23990369  0.99873173 -0.05034808 -0.06102135  0.12565808]\n",
      "[ 0.97466541 -0.22366792  0.99905304 -0.04350892  0.22451543 -0.05529895]\n",
      "[ 0.98782709 -0.15555593  0.99762432 -0.06888911  0.45443323 -0.1834217 ]\n",
      "[ 0.99789092 -0.06491316  0.99724301 -0.07420499  0.43925179  0.14507575]\n",
      "[ 0.99992106  0.01256478  0.99997356 -0.00727162  0.322715    0.5245681 ]\n",
      "[0.99623813 0.08665784 0.99798237 0.06349165 0.40649104 0.18270828]\n",
      "[0.98986408 0.142018   0.99065392 0.13639943 0.14248267 0.54545907]\n",
      "[ 0.98980822  0.14240679  0.96216185  0.27247859 -0.13378518  0.82183578]\n",
      "[ 0.99439275  0.10574994  0.91329206  0.40730531 -0.22553392  0.58693709]\n",
      "[ 0.99901011  0.0444837   0.86075496  0.50901955 -0.37407542  0.5314295 ]\n",
      "[ 0.99970412 -0.0243245   0.83165689  0.55528985 -0.29922249 -0.00265614]\n",
      "[ 0.99662437 -0.08209663  0.84680002  0.53191139 -0.26725019 -0.28227905]\n",
      "[ 0.99348954 -0.11392339  0.90374917  0.42806241 -0.04669185 -0.8930292 ]\n",
      "[ 0.99348801 -0.11393671  0.96975529  0.24407924  0.04011266 -1.03165403]\n",
      "[ 0.99607134 -0.08855439  0.99994053  0.0109062   0.200925   -1.27855395]\n",
      "[ 0.99852395 -0.05431326  0.97819154 -0.20770485  0.12828994 -0.87976247]\n",
      "[ 0.99988007 -0.01548701  0.92292145 -0.3849883   0.2465495  -0.94248473]\n",
      "[ 0.99926931  0.03822109  0.84135331 -0.54048553  0.27634079 -0.78203639]\n",
      "[ 0.99699537  0.07746116  0.7872562  -0.61662605  0.10913826 -0.13746562]\n",
      "[ 0.99770257  0.06774643  0.83006408 -0.55766803 -0.20584368  0.85927763]\n",
      "[ 0.99994374  0.01060724  0.93510905 -0.35436009 -0.35150353  1.39545152]\n",
      "[ 0.99700359 -0.07735533  0.99977701 -0.02111683 -0.49916695  1.94266857]\n",
      "[ 0.98497406 -0.17270233  0.92943963  0.36897421 -0.42394124  1.95516052]\n",
      "[ 0.97811939 -0.20804439  0.78765403  0.61611779  0.07083531  0.86946377]\n",
      "[ 0.98538304 -0.17035336  0.70838274  0.70582852  0.30431667  0.32259836]\n",
      "[ 0.99752515 -0.07031059  0.74332062  0.66893531  0.68168546 -0.8111931 ]\n",
      "[ 0.99588325  0.09064516  0.89057752  0.45483148  0.897811   -1.74446872]\n",
      "[ 0.96979726  0.24391245  0.9912246   0.13218846  0.61610067 -1.56639241]\n",
      "[ 0.94848189  0.31683136  0.99243328 -0.12278511  0.12036495 -0.93493951]\n",
      "[ 0.95438728  0.29857145  0.96610075 -0.25816532 -0.3125121  -0.42541612]\n",
      "[ 0.97717134  0.21245275  0.94786226 -0.31868031 -0.56335519 -0.20748486]\n",
      "[ 0.99628311  0.08613921  0.94028771 -0.3403807  -0.68998203 -0.03700032]\n",
      "[ 0.99799386 -0.06331082  0.95117476 -0.30865284 -0.77369012  0.34244152]\n",
      "[ 0.9807756  -0.19513896  0.96657236 -0.256394   -0.52803055  0.17038676]\n",
      "[ 0.96151014 -0.27476945  0.97550518 -0.21997645 -0.27400954  0.18464181]\n",
      "[ 0.95102741 -0.30910657  0.98760351 -0.15696914 -0.07667611  0.44177969]\n",
      "[ 0.96093532 -0.27677302  0.9928141  -0.1196669   0.40878771 -0.06480431]\n",
      "[ 0.98313646 -0.18287344  0.99407287 -0.10871586  0.53720166  0.18884743]\n",
      "[ 0.99815744 -0.06067717  0.99725294 -0.0740714   0.6708386   0.17244785]\n",
      "[9.98164333e-01 6.05637194e-02 9.99999960e-01 2.83305606e-04\n",
      " 5.20780399e-01 5.76047356e-01]\n",
      "[0.99009014 0.14043331 0.98814945 0.15349484 0.27286359 0.9450382 ]\n",
      "[0.98119545 0.1930168  0.95521353 0.29591742 0.25266405 0.50516585]\n",
      "[ 0.97749984  0.21093618  0.91257735  0.40890411 -0.07037383  0.68824912]\n",
      "[ 0.98137164  0.19211896  0.87686331  0.48073978 -0.11815489  0.10308417]\n",
      "[ 0.98602819  0.16657853  0.89617221  0.44370639 -0.13512625 -0.5222745 ]\n",
      "[ 0.99327608  0.11576974  0.93542572  0.3535233  -0.36915464 -0.45741392]\n",
      "[ 0.99927525  0.03806546  0.97051082  0.24105757 -0.39696845 -0.71611415]\n",
      "[ 0.99928114 -0.03791047  0.99684625  0.07935714 -0.35382144 -0.90587162]\n",
      "[ 0.994931   -0.10056     0.99401286 -0.10926311 -0.26975053 -0.95712134]\n",
      "[ 0.99136611 -0.13112301  0.94716783 -0.32073837 -0.04060384 -1.17869393]\n",
      "[ 0.98958463 -0.14395229  0.87757921 -0.47943167 -0.08637146 -0.53955316]\n",
      "[ 0.99030711 -0.13889503  0.82274953 -0.56840409  0.13543971 -0.49259586]\n",
      "[ 0.9945067  -0.10467295  0.79074255 -0.61214886  0.20222293 -0.03798368]\n",
      "[ 0.99875041 -0.04997628  0.79743444 -0.6034056   0.33399499  0.15854869]\n",
      "[ 0.99999755 -0.00221457  0.86437281 -0.50285151  0.13069857  1.04973209]\n",
      "[ 0.9996746   0.02550884  0.95496907 -0.29670537  0.14762464  1.17513482]\n",
      "[ 0.99949828  0.03167311  0.99999299 -0.0037454  -0.0746679   1.74575426]\n",
      "[0.99954878 0.03003733 0.95525776 0.2957746  0.0705585  1.23962213]\n",
      "[0.99812619 0.06118919 0.88813272 0.45958707 0.23568966 0.51684686]\n",
      "[ 0.99282195  0.11960173  0.87460869  0.4848295   0.33711234 -0.22137251]\n",
      "[ 0.98431328  0.17642951  0.90935802  0.41601441  0.22483964 -0.52963401]\n",
      "[ 0.97621808  0.21679082  0.9639003   0.26626341  0.17691023 -1.03864242]\n",
      "[ 0.97048532  0.2411602   0.99960621  0.02806105  0.06101414 -1.3321924 ]\n",
      "[ 0.9777767   0.20964907  0.9847712  -0.17385533 -0.38529045 -0.66508752]\n",
      "[ 0.995602    0.09368378  0.9729966  -0.23081946 -0.76584547  0.0751475 ]\n",
      "[ 0.99761348 -0.0690459   0.98219209 -0.18787947 -0.82844017  0.33046247]\n",
      "[ 0.9780875  -0.20819422  0.98868986 -0.14997453 -0.54836151  0.02462694]\n",
      "[ 0.95753383 -0.28832094  0.98831956 -0.15239571 -0.26273938 -0.06217377]\n",
      "[ 0.94802901 -0.31818391  0.98962697 -0.14366093 -0.04433071  0.14405973]\n",
      "[ 0.95652579 -0.29164775  0.99130565 -0.13157925  0.31740433 -0.01884552]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99841289,  0.05631793,  0.99730797, -0.07332681, -0.09726379,\n",
       "        0.02263332])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(observation)\n",
    "    time.sleep(0.02)\n",
    "env.close()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI = np.pi\n",
    "EPOCHS = 10000 # number of episodes\n",
    "ALPHA = 0.8 # Learning rate\n",
    "GAMMA = 0.9 # Discount factor\n",
    "NUM_BINS = 20\n",
    "\n",
    "def create_bins(num_bins_per_action = 10):\n",
    "    bins_cosine_theta1 = np.linspace(-1, 1, num_bins_per_action)\n",
    "    bins_sin_theta1 = np.linspace(-1, 1, num_bins_per_action)\n",
    "    bins_cosine_theta2 = np.linspace(-1, 1, num_bins_per_action)\n",
    "    bins_sin_theta2 = np.linspace(-1, 1, num_bins_per_action)\n",
    "    bins_angular_velocity1 = np.linspace(-4*PI, 4*PI, num_bins_per_action)\n",
    "    bins_angular_velocity2 = np.linspace(-9*PI, 9*PI, num_bins_per_action)\n",
    "    bins = np.array([bins_cosine_theta1, bins_sin_theta1, bins_cosine_theta2, bins_sin_theta2, bins_angular_velocity1, bins_angular_velocity2])\n",
    "    return bins\n",
    "\n",
    "BINS = create_bins(NUM_BINS)\n",
    "\n",
    "def discretize_observation(observations, bins):\n",
    "    binned_observations = []\n",
    "    for i , observation in enumerate(observations):\n",
    "        binned_observations.append(np.digitize(observations[i], bins[i]))\n",
    "    return tuple(binned_observations)\n",
    "\n",
    "def epsilon_greedy_action_selection(epsilon, q_table, discrete_state):\n",
    "    # EXPLORATION\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return env.action_space.sample()\n",
    "    # EXPLOITATION\n",
    "    else:\n",
    "        return np.argmax(q_table[discrete_state])\n",
    "\n",
    "def compute_next_q_value(old_q_value, reward, new_q_value):\n",
    "    return old_q_value + ALPHA * (reward + GAMMA * new_q_value - old_q_value)\n",
    "\n",
    "BURN_IN = 1\n",
    "EPSILON_END =10000\n",
    "EPSILON_REDUCE = 0.0001\n",
    "\n",
    "def reduce_epsilon(epsilon, epoch):\n",
    "    if BURN_IN <= epoch < EPSILON_END:\n",
    "        return epsilon - EPSILON_REDUCE\n",
    "    return epsilon\n",
    "\n",
    "def fail(done, points, reward):\n",
    "    if done and points > 250:\n",
    "        reward = -100\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon =1.0\n",
    "rewards = []\n",
    "log_interval = 500\n",
    "render_interval = 10000\n",
    "\n",
    "q_table_shape = (NUM_BINS, NUM_BINS, NUM_BINS, NUM_BINS, NUM_BINS, NUM_BINS, env.action_space.n)\n",
    "q_table = np.zeros(q_table_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: QtAgg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Reinforcement Learning\\Q-Learning\\acrobot.ipynb Zelle 6\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m action \u001b[39m=\u001b[39m epsilon_greedy_action_selection(epsilon, q_table, discrete_state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m new_state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m new_discrete_state \u001b[39m=\u001b[39m discretize_observation(new_state, BINS)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m old_q_value \u001b[39m=\u001b[39m q_table[discrete_state \u001b[39m+\u001b[39m (action,)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m new_q_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(q_table[new_discrete_state])\n",
      "\u001b[1;32md:\\Reinforcement Learning\\Q-Learning\\acrobot.ipynb Zelle 6\u001b[0m in \u001b[0;36mdiscretize_observation\u001b[1;34m(observations, bins)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m binned_observations \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m i , observation \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(observations):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     binned_observations\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mdigitize(observations[i], bins[i]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(binned_observations)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdigitize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:4932\u001b[0m, in \u001b[0;36mdigitize\u001b[1;34m(x, bins, right)\u001b[0m\n\u001b[0;32m   4930\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(bins) \u001b[39m-\u001b[39m _nx\u001b[39m.\u001b[39msearchsorted(bins[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], x, side\u001b[39m=\u001b[39mside)\n\u001b[0;32m   4931\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4932\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49msearchsorted(bins, x, side\u001b[39m=\u001b[39;49mside)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1350\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(a, v, side, sorter)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[0;32m   1284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearchsorted\u001b[39m(a, v, side\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, sorter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1285\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[39m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \n\u001b[0;32m   1349\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1350\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39msearchsorted\u001b[39;49m\u001b[39m'\u001b[39;49m, v, side\u001b[39m=\u001b[39;49mside, sorter\u001b[39m=\u001b[39;49msorter)\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.invert_yaxis()\n",
    "plt.ion()\n",
    "fig.canvas.draw()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "rewards = []\n",
    "mean_rewards = []\n",
    "epochs = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    initial_state = env.reset()\n",
    "    discrete_state = discretize_observation(initial_state, BINS)\n",
    "    done = False\n",
    "    points = 0\n",
    "\n",
    "    epochs.append(epoch)\n",
    "\n",
    "    while not done:\n",
    "        action = epsilon_greedy_action_selection(epsilon, q_table, discrete_state)\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        new_discrete_state = discretize_observation(new_state, BINS)\n",
    "        old_q_value = q_table[discrete_state + (action,)]\n",
    "        new_q_value = np.max(q_table[new_discrete_state])\n",
    "\n",
    "        reward = fail(done, points, reward)\n",
    "\n",
    "        q_table[discrete_state + (action,)] = compute_next_q_value(old_q_value, reward, new_q_value)\n",
    "        discrete_state = new_discrete_state\n",
    "        points += 1\n",
    "\n",
    "    \n",
    "    epsilon = reduce_epsilon(epsilon, epoch)\n",
    "    rewards.append(points)\n",
    "    mean_rewards.append(np.mean(rewards[-50:]))\n",
    "    if epoch % log_interval == 0:\n",
    "        ax.clear()\n",
    "        ax.plot(epochs, rewards, label='Rewards')\n",
    "        ax.plot(epochs, mean_rewards, label='Mean Rewards')\n",
    "        ax.invert_yaxis()\n",
    "        plt.legend()\n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.01)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "env.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with score of  382\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "rewards = 0\n",
    "for step in range(600):\n",
    "    env.render()\n",
    "    discrete_state = discretize_observation(observation, BINS)\n",
    "    action = np.argmax(q_table[discrete_state])\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    rewards += 1\n",
    "\n",
    "    if done: \n",
    "        print(\"Finished with score of \", rewards)\n",
    "        break\n",
    "    time.sleep(0.01)\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
