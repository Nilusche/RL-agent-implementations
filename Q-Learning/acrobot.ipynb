{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99522918,  0.09756471,  0.99992304,  0.01240634, -0.00124644,\n",
       "       -0.06435354])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"Acrobot-v1\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57343817  0.81924884 -0.46537616 -0.885113    1.72648526 -3.90805245]\n",
      "[-0.74314442  0.66913106 -0.91870746 -0.39493873  0.59200595 -2.94298885]\n",
      "[-0.75788012  0.65239384 -0.99748384  0.07089415 -0.33281836 -1.80639762]\n",
      "[-0.65531938  0.75535191 -0.9483254   0.31729943 -1.13454872 -0.67933584]\n",
      "[-0.37735208  0.92606987 -0.95211047  0.30575422 -2.18768572  0.82401089]\n",
      "[ 0.16436785  0.98639911 -0.99967441  0.02551606 -3.34873646  2.04783923]\n",
      "[ 0.81248815  0.58297771 -0.84637824 -0.53258227 -4.36548707  3.89162795]\n",
      "[ 0.96645823 -0.25682385 -0.05378776 -0.99855239 -4.32523643  5.67121179]\n",
      "[ 0.46317725 -0.88626567  0.94703807 -0.32112132 -3.87888544  6.98613487]\n",
      "[-0.17650802 -0.9842992   0.5498345   0.83527362 -2.569441    5.84215063]\n",
      "[-0.49214585 -0.87051276 -0.3783194   0.92567512 -0.83405203  3.99288457]\n",
      "[-0.51004702 -0.86014652 -0.88273252  0.46987583  0.60020281  2.93336763]\n",
      "[-0.27989155 -0.96003162 -0.99914256  0.04140226  1.88444902  1.51806121]\n",
      "[ 0.20676791 -0.97839002 -0.99101704 -0.13373565  3.02846137  0.26045001]\n",
      "[ 0.79365036 -0.60837415 -0.99624166 -0.08661733  3.9861064  -0.63384395]\n",
      "[ 0.98136336  0.19216125 -0.99409811  0.10848475  4.32439432 -1.18187228]\n",
      "[ 0.5391039   0.84223927 -0.95126977  0.3083599   3.62688018 -0.73818248]\n",
      "[-0.03895946  0.99924079 -0.94254473  0.33407998  2.43849976  0.54868465]\n",
      "[-0.4037956   0.91484923 -0.99546371  0.09514203  1.33792029  1.91835359]\n",
      "[-0.53939067  0.84205564 -0.91180693 -0.4106192   0.16329714  3.24676047]\n",
      "[-0.44272465  0.89665762 -0.36277989 -0.93187486 -1.32182741  4.54696638]\n",
      "[-0.01594442  0.99987288  0.67212606 -0.74043674 -3.14399627  6.70256271]\n",
      "[ 0.69688496  0.71718293  0.7657373   0.64315348 -4.47523203  7.99919591]\n",
      "[ 0.99264593 -0.12105393 -0.52276002  0.85247989 -4.68545742  6.07532289]\n",
      "[ 0.52293719 -0.85237122 -0.99988393  0.01523597 -4.12869337  4.13493069]\n",
      "[-0.15145413 -0.98846429 -0.77069238 -0.63720739 -2.85039923  2.95224599]\n",
      "[-0.56365405 -0.82601096 -0.40084356 -0.91614652 -1.66206738  1.6925511 ]\n",
      "[-0.7403919  -0.67217545 -0.21023462 -0.97765096 -0.72223365  0.3031044 ]\n",
      "[-0.78224908 -0.6229658  -0.28741132 -0.95780725  0.05593624 -1.0931823 ]\n",
      "[-0.72334632 -0.69048541 -0.61825866 -0.7859747   0.83579376 -2.63700646]\n",
      "[-0.52946161 -0.8483339  -0.9734749  -0.22879385  1.71474921 -4.09756689]\n",
      "[-0.10670377 -0.99429086 -0.75772227  0.65257717  2.86272683 -5.42853868]\n",
      "[ 0.5868061  -0.80972748  0.48054641  0.8769693   4.56547496 -8.50896356]\n",
      "[ 0.99753786  0.07013006  0.69603295 -0.71800984  5.11841567 -9.06356723]\n",
      "[ 0.55135027  0.83427387 -0.63368048 -0.77359489  4.05534792 -5.64461596]\n",
      "[-0.1239916   0.99228327 -0.99835971  0.05725288  2.97910113 -3.93908685]\n",
      "[-0.57101053  0.82094274 -0.74733622  0.66444607  1.8970844  -2.79000046]\n",
      "[-0.78100244  0.62452797 -0.40381517  0.91484059  1.03029672 -1.48966587]\n",
      "[-0.85395342  0.52034946 -0.26928913  0.96305938  0.26285523  0.06033141]\n",
      "[-0.85343193  0.52120431 -0.38198503  0.92416851 -0.26613711  1.12599284]\n",
      "[-0.78488312  0.61964385 -0.69149281  0.72238334 -0.94006882  2.57384354]\n",
      "[-0.60433545  0.79672998 -0.98128557  0.19255812 -1.64853275  3.57084057]\n",
      "[-0.21525275  0.97655837 -0.80519975 -0.59300367 -2.73025453  4.80137108]\n",
      "[ 0.44522509  0.89541869  0.22049649 -0.97538777 -4.10111399  7.02452633]\n",
      "[ 0.98801164  0.15437938  0.94951557  0.31371992 -5.12146769  8.85343906]\n",
      "[ 0.69954452 -0.71458902 -0.24493909  0.96953847 -4.27069498  5.86935545]\n",
      "[ 0.02184153 -0.99976145 -0.92108039  0.38937247 -3.21699317  3.55560072]\n",
      "[-0.48706771 -0.87336421 -0.9854183  -0.17014929 -2.10457332  2.22984988]\n",
      "[-0.74252213 -0.66982153 -0.87349705 -0.48682943 -1.22648473  1.16885999]\n",
      "[-0.84356573 -0.53702594 -0.82272406 -0.56844095 -0.47839078 -0.19193262]\n",
      "[-0.86082597 -0.50889944 -0.90530665 -0.42475861  0.13832312 -1.4462946 ]\n",
      "[-0.81080312 -0.58531897 -0.99941912 -0.03407971  0.80394691 -2.58521333]\n",
      "[-0.64998065 -0.75995076 -0.84949885  0.52759047  1.63275961 -3.3369955 ]\n",
      "[-0.26088867 -0.9653689  -0.22134659  0.97519521  2.85721379 -4.71934148]\n",
      "[ 0.44299428 -0.89652444  0.8156218   0.57858541  4.40140187 -7.17266233]\n",
      "[ 0.98823881 -0.15291844  0.64624346 -0.76313131  4.89278729 -6.88254168]\n",
      "[ 0.70140132  0.71276657 -0.40481757 -0.91439747  4.48638122 -4.23225681]\n",
      "[-0.0167584   0.99985957 -0.83498077 -0.55027912  3.37400118 -1.62791466]\n",
      "[-0.53718703  0.84346315 -0.90837407 -0.41815852  2.14481388  0.00382413]\n",
      "[-0.77119353  0.63660077 -0.84442678 -0.53567099  1.02012187  1.2482316 ]\n",
      "[-8.31453904e-01  5.55593742e-01 -6.20035907e-01 -7.84573434e-01\n",
      " -1.69712247e-03  2.06456724e+00]\n",
      "[-0.77055273  0.63737625 -0.18948904 -0.98188284 -1.02668876  2.72490407]\n",
      "[-0.54958499  0.83543781  0.37977625 -0.92507838 -1.97361502  3.14636288]\n",
      "[-0.05250064  0.99862089  0.92066454 -0.39035473 -3.36315602  4.75547831]\n",
      "[ 0.68447071  0.72904036  0.77940191  0.62652428 -4.57973117  5.61469151]\n",
      "[ 0.99207926 -0.12561348 -0.02102781  0.99977889 -4.70388335  3.24239921]\n",
      "[ 0.54139777 -0.84076658 -0.36471284  0.93112005 -3.81686254  0.24755312]\n",
      "[-0.01194967 -0.9999286  -0.13833357  0.99038569 -1.91684373 -2.4971902 ]\n",
      "[-0.16757045 -0.9858601   0.5725778   0.81985039  0.33961686 -4.92181255]\n",
      "[ 0.07812033 -0.99694394  0.9812551  -0.19271335  1.95962442 -6.40422751]\n",
      "[ 0.524309   -0.85152808  0.06747457 -0.99772099  2.67525881 -6.485088  ]\n",
      "[ 0.9087255  -0.41739425 -0.92773796 -0.3732322   3.21523798 -6.17564487]\n",
      "[ 0.97337602  0.22921416 -0.64490796  0.76426024  3.30385642 -6.52042704]\n",
      "[ 0.62464805  0.7809064   0.69135134  0.72251874  3.36842548 -8.20150419]\n",
      "[ 0.07337311  0.99730456  0.66684451 -0.74519689  2.28747085 -7.62253474]\n",
      "[-0.13186927  0.99126712 -0.48716507 -0.87330991 -0.22127595 -4.88342581]\n",
      "[ 0.12675188  0.99193445 -0.95141529 -0.30791061 -2.24136972 -2.66121069]\n",
      "[ 0.65585741  0.7548848  -0.99943144  0.03371647 -3.53387003 -0.93711805]\n",
      "[ 0.99703518  0.07694708 -0.99123635  0.13210031 -4.1058219  -0.27139098]\n",
      "[ 0.75253143 -0.65855634 -0.97319701  0.22997301 -3.68563167 -0.94212294]\n",
      "[ 0.23874221 -0.97108298 -0.82620364  0.56337158 -2.27109037 -2.84708625]\n",
      "[ 4.96014823e-05 -9.99999999e-01 -1.72804071e-01  9.84956219e-01\n",
      " -3.35238947e-02 -5.18199698e+00]\n",
      "[ 0.22567903 -0.97420171  0.88791299  0.46001143  2.2015444  -7.41644455]\n",
      "[ 0.69848793 -0.71562184  0.4796126  -0.87748034  2.95283642 -7.51487497]\n",
      "[ 0.97888646 -0.20440474 -0.76641418 -0.64234672  2.98538045 -6.32835191]\n",
      "[ 0.92425452  0.38177688 -0.85543425  0.51791142  2.91686047 -6.26293971]\n",
      "[ 0.58850902  0.80849065  0.27426849  0.96165316  2.61018548 -6.8978776 ]\n",
      "[ 0.14650118  0.9892105   0.98998844 -0.14114845  2.01049871 -7.0851052 ]\n",
      "[-0.07321824  0.99731594  0.17727414 -0.98416151  0.01347631 -5.21199053]\n",
      "[ 0.17579515  0.98442677 -0.55820444 -0.82970344 -2.44795487 -2.47784059]\n",
      "[ 0.74715999  0.66464423 -0.75009644 -0.66132846 -4.06360247 -0.10120496]\n",
      "[ 0.98700319 -0.16070067 -0.5830213  -0.81245687 -4.58638213  2.23558344]\n",
      "[ 0.5279454  -0.84927831 -0.04337925 -0.99905868 -3.80603699  3.34451038]\n",
      "[-0.07739402 -0.99700058  0.56498604 -0.82510046 -2.50677113  2.89349413]\n",
      "[-0.45320242 -0.89140763  0.90221444 -0.43128772 -1.44341335  2.31123079]\n",
      "[-0.59567249 -0.80322742  0.99374605 -0.11166377 -0.25255086  1.05129168]\n",
      "[-0.55498485 -0.83186046  0.99983185  0.01833785  0.75401374  0.25949737]\n",
      "[-0.32394617 -0.94607552  0.99992906 -0.01191119  1.85412825 -0.58132413]\n",
      "[ 0.16051282 -0.98703376  0.97642296 -0.21586615  3.05397531 -1.43529516]\n",
      "[ 0.76552032 -0.64341172  0.86088744 -0.50879545  3.94019436 -1.49864466]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99993494, -0.01140652,  0.99593561, -0.09006805, -0.01420477,\n",
       "        0.0370999 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(observation)\n",
    "    time.sleep(0.02)\n",
    "env.close()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI = np.pi\n",
    "EPOCHS = 10000 # number of episodes\n",
    "ALPHA = 0.8 # Learning rate\n",
    "GAMMA = 0.9 # Discount factor\n",
    "NUM_BINS = 15\n",
    "\n",
    "def create_bins(num_bins_per_action = 10):\n",
    "    bins_cosine_theta1 = np.linspace(-1, 1, num_bins_per_action)\n",
    "    bins_sin_theta1 = np.linspace(-1, 1, num_bins_per_action)\n",
    "    bins_cosine_theta2 = np.linspace(-1, 1, num_bins_per_action)\n",
    "    bins_sin_theta2 = np.linspace(-1, 1, num_bins_per_action)\n",
    "    bins_angular_velocity1 = np.linspace(-4*PI, 4*PI, num_bins_per_action)\n",
    "    bins_angular_velocity2 = np.linspace(-9*PI, 9*PI, num_bins_per_action)\n",
    "    bins = np.array([bins_cosine_theta1, bins_sin_theta1, bins_cosine_theta2, bins_sin_theta2, bins_angular_velocity1, bins_angular_velocity2])\n",
    "    return bins\n",
    "\n",
    "BINS = create_bins(NUM_BINS)\n",
    "\n",
    "def discretize_observation(observations, bins):\n",
    "    binned_observations = []\n",
    "    for i , observation in enumerate(observations):\n",
    "        binned_observations.append(np.digitize(observations[i], bins[i]))\n",
    "    return tuple(binned_observations)\n",
    "\n",
    "def epsilon_greedy_action_selection(epsilon, q_table, discrete_state):\n",
    "    # EXPLORATION\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return env.action_space.sample()\n",
    "    # EXPLOITATION\n",
    "    else:\n",
    "        return np.argmax(q_table[discrete_state])\n",
    "\n",
    "def compute_next_q_value(old_q_value, reward, new_q_value):\n",
    "    return old_q_value + ALPHA * (reward + GAMMA * new_q_value - old_q_value)\n",
    "\n",
    "BURN_IN = 1\n",
    "EPSILON_END =10000\n",
    "EPSILON_REDUCE = 0.0001\n",
    "\n",
    "def reduce_epsilon(epsilon, epoch):\n",
    "    if BURN_IN <= epoch < EPSILON_END:\n",
    "        return epsilon - EPSILON_REDUCE\n",
    "    return epsilon\n",
    "\n",
    "def fail(done, points, reward):\n",
    "    if done and points > 250:\n",
    "        reward = -100\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon =1.0\n",
    "rewards = []\n",
    "log_interval = 500\n",
    "render_interval = 10000\n",
    "\n",
    "q_table_shape = (NUM_BINS, NUM_BINS, NUM_BINS, NUM_BINS, NUM_BINS, NUM_BINS, env.action_space.n)\n",
    "q_table = np.zeros(q_table_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: QtAgg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Reinforcement Learning\\Q-Learning\\acrobot.ipynb Zelle 6\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m action \u001b[39m=\u001b[39m epsilon_greedy_action_selection(epsilon, q_table, discrete_state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m new_state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m new_discrete_state \u001b[39m=\u001b[39m discretize_observation(new_state, BINS)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m old_q_value \u001b[39m=\u001b[39m q_table[discrete_state \u001b[39m+\u001b[39m (action,)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m new_q_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(q_table[new_discrete_state])\n",
      "\u001b[1;32md:\\Reinforcement Learning\\Q-Learning\\acrobot.ipynb Zelle 6\u001b[0m in \u001b[0;36mdiscretize_observation\u001b[1;34m(observations, bins)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m binned_observations \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m i , observation \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(observations):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     binned_observations\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mdigitize(observations[i], bins[i]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinforcement%20Learning/Q-Learning/acrobot.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(binned_observations)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdigitize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:4932\u001b[0m, in \u001b[0;36mdigitize\u001b[1;34m(x, bins, right)\u001b[0m\n\u001b[0;32m   4930\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(bins) \u001b[39m-\u001b[39m _nx\u001b[39m.\u001b[39msearchsorted(bins[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], x, side\u001b[39m=\u001b[39mside)\n\u001b[0;32m   4931\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4932\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49msearchsorted(bins, x, side\u001b[39m=\u001b[39;49mside)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1350\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(a, v, side, sorter)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[0;32m   1284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearchsorted\u001b[39m(a, v, side\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, sorter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1285\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[39m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \n\u001b[0;32m   1349\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1350\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39msearchsorted\u001b[39;49m\u001b[39m'\u001b[39;49m, v, side\u001b[39m=\u001b[39;49mside, sorter\u001b[39m=\u001b[39;49msorter)\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.invert_yaxis()\n",
    "plt.ion()\n",
    "fig.canvas.draw()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "rewards = []\n",
    "mean_rewards = []\n",
    "epochs = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    initial_state = env.reset()\n",
    "    discrete_state = discretize_observation(initial_state, BINS)\n",
    "    done = False\n",
    "    points = 0\n",
    "\n",
    "    epochs.append(epoch)\n",
    "\n",
    "    while not done:\n",
    "        action = epsilon_greedy_action_selection(epsilon, q_table, discrete_state)\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        new_discrete_state = discretize_observation(new_state, BINS)\n",
    "        old_q_value = q_table[discrete_state + (action,)]\n",
    "        new_q_value = np.max(q_table[new_discrete_state])\n",
    "\n",
    "        reward = fail(done, points, reward)\n",
    "\n",
    "        q_table[discrete_state + (action,)] = compute_next_q_value(old_q_value, reward, new_q_value)\n",
    "        discrete_state = new_discrete_state\n",
    "        points += 1\n",
    "\n",
    "    \n",
    "    epsilon = reduce_epsilon(epsilon, epoch)\n",
    "    rewards.append(points)\n",
    "    mean_rewards.append(np.mean(rewards[-50:]))\n",
    "    if epoch % log_interval == 0:\n",
    "        ax.clear()\n",
    "        ax.plot(epochs, rewards, label='Rewards')\n",
    "        ax.plot(epochs, mean_rewards, label='Mean Rewards')\n",
    "        ax.invert_yaxis()\n",
    "        plt.legend()\n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.01)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "env.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with score of  382\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "rewards = 0\n",
    "for step in range(600):\n",
    "    env.render()\n",
    "    discrete_state = discretize_observation(observation, BINS)\n",
    "    action = np.argmax(q_table[discrete_state])\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    rewards += 1\n",
    "\n",
    "    if done: \n",
    "        print(\"Finished with score of \", rewards)\n",
    "        break\n",
    "    time.sleep(0.01)\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
